{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbrQY-Km28gl"
      },
      "source": [
        "## Imports üôÖüèª‚Äç‚ôÇÔ∏èüôÖüèª‚Äç‚ôÄÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6IEKJHz28gq",
        "outputId": "fd5fd5b1-79f6-44dc-993b-bb03091be487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.8.1.78)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.24.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "!pip install opencv-python\n",
        "import matplotlib.pyplot as ajeeb\n",
        "import cv2\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib import image as mpimg\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from scipy import linalg\n",
        "from scipy.linalg import null_space\n",
        "# !pip install imageio\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21gzew0w28gt"
      },
      "source": [
        "## TASK-02 (45 MARKS)üï∑Ô∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKcwJ5KQ28gu"
      },
      "source": [
        "### Pre-Processing (2 Marks)\n",
        "- Justify each step of your pre-processing in comments\n",
        "- Save the final pre-process images to the same directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SV7Kxii28gv"
      },
      "outputs": [],
      "source": [
        "# Add your code here\n",
        "# Load the two images\n",
        "def normalize_image(image):\n",
        "    # I need to convert the resized images to grayscaling\n",
        "    # We need to do homography matrix calculations ahead and as in the tutorial grayscaling the images is necessary\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    normalize_image = cv2.normalize(gray_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    # I need to resize the images to the same dimensions so that they both come to a common scale and same hieght and width\n",
        "    # I did this to make it compulsory that the images have the same scale\n",
        "    # Resizing the image will also help in lower values of the matrices when doing homography matrix calculations\n",
        "    normalize_image= cv2.resize(image, (600, 600))\n",
        "    return normalize_image\n",
        "\n",
        "image1 = cv2.imread(r\"C:\\Users\\dell\\Documents\\25100287_PA3\\topview.jpeg\")\n",
        "image2 = cv2.imread(r\"C:\\Users\\dell\\Documents\\25100287_PA3\\warped_370.jpg\")\n",
        "\n",
        "image1 = normalize_image(image1)\n",
        "image2 = normalize_image(image2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ib4rqsh28gz"
      },
      "source": [
        "### Reading image points\n",
        "\n",
        "Load the first image you're about to stitch and mark some points that you find in the second image too. The `point_reader()` function from `StudentID_PA3.py` will be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmyPZiyA28g0"
      },
      "source": [
        "### Reading the first image's points (4 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGQUMvWF28g1"
      },
      "outputs": [],
      "source": [
        "def point_reader(img):\n",
        "    '''\n",
        "    img - The image to be marked points on\n",
        "    '''\n",
        "    img_with_points = img.copy()\n",
        "\n",
        "    points = []\n",
        "    def click_event(event, x, y, flags, param):\n",
        "        nonlocal points\n",
        "        if event == cv2.EVENT_LBUTTONDOWN:\n",
        "            cv2.circle(img_with_points, (x, y), 5, (0, 255, 0), -1)\n",
        "            points.append((x, y))\n",
        "\n",
        "            cv2.imshow('Image', img_with_points)\n",
        "\n",
        "    cv2.imshow('Image', img_with_points)\n",
        "    cv2.setMouseCallback('Image', click_event)\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    points_array = np.array(points)\n",
        "\n",
        "    return points_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWnP5-R428g2",
        "outputId": "ed770f12-9567-4c6b-92db-f9163fac05bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[325 355]\n",
            " [345 296]\n",
            " [327 272]\n",
            " [343 331]]\n"
          ]
        }
      ],
      "source": [
        "# Save your points in an np.array\n",
        "img1_points = point_reader(image1)\n",
        "print(img1_points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5qIV07q28g3"
      },
      "source": [
        "### Reading the first image's points (4 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfYAj2pl28g4",
        "outputId": "59f93cc1-2709-45cf-b0c5-20d5db711edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[435 406]\n",
            " [439 332]\n",
            " [439 286]\n",
            " [438 253]]\n"
          ]
        }
      ],
      "source": [
        "# Save your points in an np.array\n",
        "img2_points = point_reader(image2)\n",
        "print(img2_points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3K7oXVK28g5"
      },
      "source": [
        "### Finding Homography (25 Marks)\n",
        "You are required to calculate the homography matrix H.\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x'  \\\\\n",
        "y'  \\\\\n",
        "h\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "h_1 & h_2 & h_3 \\\\\n",
        "h_4 & h_5 & h_6 \\\\\n",
        "h_7 & h_8 & h_9\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "x  \\\\\n",
        "y  \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "You can use the strategy from WA-1, Q#7 to solve this =)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXZuj8Du28g6"
      },
      "outputs": [],
      "source": [
        "# We are creating the canvas which is essentially the two images joined together\n",
        "row1, col1 = image1.shape[:2]\n",
        "row2, col2 = image2.shape[:2]\n",
        "\n",
        "canvas = np.zeros((max(row1, row2), col1 + col2, 3), dtype='uint8')\n",
        "\n",
        "# We are placing the first image on the left side of the canvas\n",
        "canvas[:row1, :col1, :] = image1\n",
        "# We are placing the second image on the right side of the canvas\n",
        "canvas[:row2, col1:col1 + col2, :] = image2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNFbsief28g7"
      },
      "outputs": [],
      "source": [
        "img2_points[:,0] = img2_points[:,0] + col1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqKUIdy628g8",
        "outputId": "436739b7-866d-403d-9af2-1f918d1eb676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[    325     355       1       0       0       0 -336375 -367425   -1035]\n",
            " [      0       0       0     325     355       1 -131950 -144130    -406]\n",
            " [    345     296       1       0       0       0 -358455 -307544   -1039]\n",
            " [      0       0       0     345     296       1 -114540  -98272    -332]\n",
            " [    327     272       1       0       0       0 -339753 -282608   -1039]\n",
            " [      0       0       0     327     272       1  -93522  -77792    -286]\n",
            " [    343     331       1       0       0       0 -356034 -343578   -1038]\n",
            " [      0       0       0     343     331       1  -86779  -83743    -253]]\n"
          ]
        }
      ],
      "source": [
        "# DUMP YOUR CODE\n",
        "# We will now zip the points together\n",
        "points = list(zip(img1_points, img2_points))\n",
        "\n",
        "homoArray = []\n",
        "for point1, point2 in points:\n",
        "    homoArray.append([point1[0], point1[1], 1, 0, 0, 0, -point2[0] * point1[0], -point2[0] * point1[1], -point2[0]])\n",
        "    homoArray.append([0, 0, 0, point1[0], point1[1], 1, -point2[1] * point1[0], -point2[1] * point1[1], -point2[1]])\n",
        "\n",
        "homoArray = np.array(homoArray)\n",
        "print(homoArray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf3mPGPf28g8"
      },
      "source": [
        "### Calculating SVD\n",
        "This part has been done for you üôåüèª"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgpOMQH-28g9",
        "outputId": "b5f40121-4165-4f08-b8b2-59c0cb01ce82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Homography matrix\n",
            " [[-1.80520470e-03 -1.09855567e-03  9.68655843e-01]\n",
            " [-4.32998226e-04 -3.12163571e-04  2.48395326e-01]\n",
            " [-1.73697989e-06 -1.05766854e-06  9.32239157e-04]]\n"
          ]
        }
      ],
      "source": [
        "# List of useful functions\n",
        "u, s, vh = np.linalg.svd(homoArray) # Replace it with your H matrix\n",
        "vh = np.transpose(vh)\n",
        "P = vh[:,len(vh[0])-1]\n",
        "\n",
        "P = np.array([P[0:3], P[3:6], P[6:9]])\n",
        "print(\"Homography matrix\\n\",P)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Correspondences for the top view image\n",
        "points_top_view = np.array([[325, 355], [345, 296], [327, 272], [343, 331]], dtype=np.float32)\n",
        "\n",
        "# Correspondences for the original image\n",
        "points_original = np.array([[435, 406], [439, 332], [439, 286], [438, 253]], dtype=np.float32)\n",
        "\n",
        "# Homography matrix\n",
        "homography_matrix = np.array([[-1.80520470e-03, -1.09855567e-03, 9.68655843e-01],\n",
        "                              [-4.32998226e-04, -3.12163571e-04, 2.48395326e-01],\n",
        "                              [-1.73697989e-06, -1.05766854e-06, 9.32239157e-04]])\n",
        "\n",
        "# GPS coordinates for the corresponding points in both images\n",
        "gps_top_view = np.array([31.470009, 74.405807], dtype=np.float32)\n",
        "gps_original = np.array([31.469930, 74.405771], dtype=np.float32)\n",
        "\n",
        "# Use the homography matrix to map original image points to the top view\n",
        "points_original_reshape = points_original.reshape(-1, 1, 2)\n",
        "mapped_points_original = cv2.perspectiveTransform(points_original_reshape, homography_matrix)\n",
        "\n",
        "# Calculate deviation/error using Euclidean distance\n",
        "pixel_error = np.mean(np.linalg.norm(mapped_points_original.squeeze() - points_top_view, axis=1))\n",
        "\n",
        "# Use the homography matrix to transform original GPS coordinates to top view GPS coordinates\n",
        "gps_original_reshape = gps_original.reshape(-1, 1, 2)\n",
        "mapped_gps_original = cv2.perspectiveTransform(gps_original_reshape, homography_matrix)\n",
        "\n",
        "# Calculate deviation/error in GPS coordinates\n",
        "gps_error = np.linalg.norm(mapped_gps_original.squeeze() - gps_top_view)\n",
        "\n",
        "# Calculate error percentage\n",
        "pixel_error_percentage = (pixel_error / np.mean(np.linalg.norm(points_top_view, axis=1))) * 100\n",
        "\n",
        "print(f\"Pixel Deviation/Error: {pixel_error} pixels\")\n",
        "print(f\"GPS Deviation/Error: {gps_error} degrees\")\n",
        "print(f\"pixel_error_percentage: {pixel_error_percentage}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBxujlC8sQHl",
        "outputId": "829696b2-43b7-4abd-cff3-4f6b6fc62eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixel Deviation/Error: 408.98034 pixels\n",
            "GPS Deviation/Error: 725.4488 degrees\n",
            "pixel_error_percentage: 31.30375\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}